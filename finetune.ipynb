{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "562c001f",
   "metadata": {},
   "source": [
    "Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "609fac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== BERT-OPTIMIZED TURKISH ADDRESS PREPROCESSING =====\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "def bert_optimized_address_preprocessing(text):\n",
    "    \"\"\"\n",
    "    BERT modeli iÃ§in optimize edilmiÅŸ TÃ¼rkÃ§e adres preprocessing fonksiyonu.\n",
    "    TÃ¼m preprocessing adÄ±mlarÄ±nÄ± birleÅŸtirir ve BERT'in en iyi performansÄ± iÃ§in tasarlanmÄ±ÅŸtÄ±r.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return \"\"\n",
    "    \n",
    "    # Orijinal metni koru (bazÄ± analizler iÃ§in)\n",
    "    original_text = text\n",
    "    \n",
    "    # --- PHASE 1: INITIAL CLEANING ---\n",
    "    # KÃ¼Ã§Ã¼k harfe Ã§evir\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    # Ã‡oklu boÅŸluklarÄ± ve tab/newline karakterlerini temizle\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # --- PHASE 2: TURKISH CHARACTER NORMALIZATION ---\n",
    "    # TÃ¼rkÃ§e karakterleri kontrollÃ¼ ÅŸekilde normalize et (BERT tÃ¼rkÃ§e modeli iÃ§in optimize)\n",
    "    turkish_normalization = {\n",
    "        'Ã§': 'c', 'ÄŸ': 'g', 'Ä±': 'i', 'Ã¶': 'o', 'ÅŸ': 's', 'Ã¼': 'u',\n",
    "        'Ã¢': 'a', 'Ã®': 'i', 'Ã»': 'u', 'Ã´': 'o'\n",
    "    }\n",
    "    for tr_char, en_char in turkish_normalization.items():\n",
    "        text = text.replace(tr_char, en_char)\n",
    "    \n",
    "    # --- PHASE 3: NUMBER & ALPHANUMERIC STANDARDIZATION ---\n",
    "    # SayÄ± ve alfanÃ¼merik kodlarÄ± standardize et (BERT tokenization iÃ§in)\n",
    "    \n",
    "    # AlfanÃ¼merik kodlarÄ± ayÄ±r: 24/A â†’ 24 A, 12/B â†’ 12 B\n",
    "    text = re.sub(r'\\b(\\d+)\\s*[/\\-\\\\]\\s*([a-zA-Z]\\d*)\\b', r'\\1 \\2', text)\n",
    "    \n",
    "    # SayÄ± kombinasyonlarÄ±nÄ± ayÄ±r: 24/5 â†’ 24 5, 3/12 â†’ 3 12  \n",
    "    text = re.sub(r'\\b(\\d+)\\s*[/\\-\\\\]\\s*(\\d+)\\b', r'\\1 \\2', text)\n",
    "    \n",
    "    # NoktalÄ± sayÄ±larÄ± ayÄ±r: 24.5 â†’ 24 5 (BERT iÃ§in)\n",
    "    text = re.sub(r'\\b(\\d+)[.,](\\d+)\\b', r'\\1 \\2', text)\n",
    "    \n",
    "    # --- PHASE 4: COMPREHENSIVE ABBREVIATION EXPANSION ---\n",
    "    # TÃ¼rkiye'de yaygÄ±n kullanÄ±lan adres kÄ±saltmalarÄ±\n",
    "    abbreviations = {\n",
    "        # Temel adres bileÅŸenleri\n",
    "        r'\\bmah\\.?\\b': 'mahallesi',\n",
    "        r'\\bmahalle\\b': 'mahallesi',\n",
    "        r'\\bmhl\\.?\\b': 'mahallesi',\n",
    "        \n",
    "        r'\\bsok\\.?\\b': 'sokak',\n",
    "        r'\\bsk\\.?\\b': 'sokak',\n",
    "        r'\\bsokagi\\b': 'sokak',\n",
    "        \n",
    "        r'\\bcad\\.?\\b': 'caddesi',\n",
    "        r'\\bcd\\.?\\b': 'caddesi',\n",
    "        r'\\bcaddesi\\b': 'caddesi',\n",
    "        \n",
    "        r'\\bblv\\.?\\b': 'bulvari',\n",
    "        r'\\bbulvar\\b': 'bulvari',\n",
    "        r'\\bblvr\\.?\\b': 'bulvari',\n",
    "        \n",
    "        r'\\bno\\.?\\b': 'numara',\n",
    "        r'\\bnumara\\b': 'numara',\n",
    "        r'\\bnum\\.?\\b': 'numara',\n",
    "        \n",
    "        # YapÄ± bileÅŸenleri\n",
    "        r'\\bapt\\.?\\b': 'apartmani',\n",
    "        r'\\bapartman\\b': 'apartmani',\n",
    "        r'\\bapart\\.?\\b': 'apartmani',\n",
    "        \n",
    "        r'\\bd\\.?\\b': 'daire',\n",
    "        r'\\bdaire\\b': 'daire',\n",
    "        r'\\bdr\\.?\\b': 'daire',\n",
    "        \n",
    "        r'\\bk\\.?\\b': 'kat',\n",
    "        r'\\bkat\\b': 'kat',\n",
    "        r'\\bkati\\b': 'kat',\n",
    "        \n",
    "        r'\\bblok\\b': 'blok',\n",
    "        r'\\bbl\\.?\\b': 'blok',\n",
    "        \n",
    "        # Site ve kompleks\n",
    "        r'\\bsit\\.?\\b': 'sitesi',\n",
    "        r'\\bsite\\b': 'sitesi',\n",
    "        r'\\bkonut\\.?\\b': 'konutlari',\n",
    "        r'\\bkompleks\\b': 'kompleksi',\n",
    "        r'\\brezidans\\b': 'rezidansi',\n",
    "        \n",
    "        # DiÄŸer yaygÄ±n kÄ±saltmalar\n",
    "        r'\\bpk\\.?\\b': 'park',\n",
    "        r'\\bpark\\b': 'park',\n",
    "        r'\\bmez\\.?\\b': 'mezarligi',\n",
    "        r'\\bmeydan\\b': 'meydani',\n",
    "        r'\\bmeyd\\.?\\b': 'meydani',\n",
    "        r'\\bÃ§Ä±k\\.?\\b': 'cikmazÄ±',\n",
    "        r'\\bÃ§Ä±kmaz\\b': 'cikmazÄ±'\n",
    "    }\n",
    "    \n",
    "    for abbr_pattern, full_form in abbreviations.items():\n",
    "        text = re.sub(abbr_pattern, full_form, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # --- PHASE 5: GEOGRAPHIC STANDARDIZATION ---\n",
    "    # YÃ¶n ve konum belirteÃ§leri\n",
    "    directional_terms = {\n",
    "        r'\\bkuzey\\b': 'kuzey',\n",
    "        r'\\bguney\\b': 'guney',\n",
    "        r'\\bdogu\\b': 'dogu',\n",
    "        r'\\bbati\\b': 'bati',\n",
    "        r'\\biÃ§\\b': 'ic',\n",
    "        r'\\biÃ§i\\b': 'ic',\n",
    "        r'\\bdÄ±ÅŸ\\b': 'dis',\n",
    "        r'\\bdÄ±ÅŸÄ±\\b': 'dis',\n",
    "        r'\\balt\\b': 'alt',\n",
    "        r'\\bÃ¼st\\b': 'ust',\n",
    "        r'\\bÃ¶n\\b': 'on',\n",
    "        r'\\barka\\b': 'arka',\n",
    "        r'\\bsag\\b': 'sag',\n",
    "        r'\\bsol\\b': 'sol'\n",
    "    }\n",
    "    \n",
    "    for direction_pattern, standardized in directional_terms.items():\n",
    "        text = re.sub(direction_pattern, standardized, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # --- PHASE 6: CITY/DISTRICT NORMALIZATION ---\n",
    "    # BÃ¼yÃ¼k ÅŸehir ve ilÃ§e isimleri standardizasyonu\n",
    "    major_locations = {\n",
    "        r'\\bist\\.?\\b': 'istanbul',\n",
    "        r'\\bistanbul\\b': 'istanbul',\n",
    "        r'\\bank\\.?\\b': 'ankara',\n",
    "        r'\\bankara\\b': 'ankara',\n",
    "        r'\\bizm\\.?\\b': 'izmir',\n",
    "        r'\\bizmir\\b': 'izmir',\n",
    "        r'\\bbeyoglu\\b': 'beyoglu',\n",
    "        r'\\bkadikoy\\b': 'kadikoy',\n",
    "        r'\\bbesiktas\\b': 'besiktas',\n",
    "        r'\\buskudar\\b': 'uskudar',\n",
    "        r'\\bsisli\\b': 'sisli',\n",
    "        r'\\bfatih\\b': 'fatih',\n",
    "        r'\\besenler\\b': 'esenler',\n",
    "        r'\\bbahcelievler\\b': 'bahcelievler'\n",
    "    }\n",
    "    \n",
    "    for location_pattern, standardized in major_locations.items():\n",
    "        text = re.sub(location_pattern, standardized, text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # --- PHASE 7: NOISE REMOVAL ---\n",
    "    # Gereksiz kelime ve ifadeleri kaldÄ±r\n",
    "    noise_patterns = [\n",
    "        r'\\bmevki\\b', r'\\bmevkii\\b', r'\\byakini\\b', r'\\bcivarÄ±\\b',\n",
    "        r'\\bkarsisi\\b', r'\\bkarsisinda\\b', r'\\byani\\b', r'\\byaninda\\b',\n",
    "        r'\\bonu\\b', r'\\bonunde\\b', r'\\barkasi\\b', r'\\barkasinda\\b',\n",
    "        r'\\biÃ§inde\\b', r'\\biÃ§erisinde\\b', r'\\buzerinde\\b', r'\\baltinda\\b'\n",
    "    ]\n",
    "    \n",
    "    for noise_pattern in noise_patterns:\n",
    "        text = re.sub(noise_pattern, '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # --- PHASE 8: FEATURE EXTRACTION & TAGGING ---\n",
    "    features = []\n",
    "    \n",
    "    # Posta kodu tespiti ve DOÄžRUDAN EKLEME (generic tag yerine)\n",
    "    postal_matches = re.findall(r'\\b\\d{5}\\b', original_text)\n",
    "    if postal_matches:\n",
    "        # En bÃ¼yÃ¼k posta kodunu al (Ã§oklu varsa en Ã¶nemlisi genelde bÃ¼yÃ¼k olandÄ±r)\n",
    "        main_postal = max(postal_matches)\n",
    "        features.append(f'POSTAL_{main_postal}')\n",
    "    \n",
    "    # Apartman tespiti\n",
    "    if re.search(r'\\b(apt|apartman|apart)\\b', original_text, re.IGNORECASE):\n",
    "        features.append('APARTMENT')\n",
    "    \n",
    "    # Kat bilgisi tespiti\n",
    "    if re.search(r'\\b(\\d+\\.?\\s*(kat|kati)|kat\\s*\\d+|(zemin|bodrum|cati)\\s*kat)\\b', original_text, re.IGNORECASE):\n",
    "        features.append('FLOOR_INFO')\n",
    "    \n",
    "    # Daire/kapÄ± numarasÄ± tespiti\n",
    "    if re.search(r'\\b(daire|d\\.)\\s*\\d+\\b', original_text, re.IGNORECASE):\n",
    "        features.append('UNIT_NUMBER')\n",
    "    \n",
    "    # Site/kompleks tespiti\n",
    "    if re.search(r'\\b(site|sitesi|kompleks|kompleksi|rezidans|rezidansi|konut)\\b', original_text, re.IGNORECASE):\n",
    "        features.append('COMPLEX')\n",
    "    \n",
    "    # Blok bilgisi tespiti\n",
    "    if re.search(r'\\b(blok|bl\\.?)\\s*[a-zA-Z0-9]\\b', original_text, re.IGNORECASE):\n",
    "        features.append('BLOCK_INFO')\n",
    "    \n",
    "    # --- PHASE 9: FINAL CLEANUP ---\n",
    "    # Ã–zel karakterleri ve noktalamayÄ± temizle (BERT iÃ§in)\n",
    "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
    "    \n",
    "    # Fazla boÅŸluklarÄ± temizle\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    # AKILLI KELÄ°ME FÄ°LTRELEME: AnlamlÄ± tek harfleri koru!\n",
    "    words = text.split()\n",
    "    filtered_words = []\n",
    "    for i, word in enumerate(words):\n",
    "        # SayÄ±larÄ± her zaman koru\n",
    "        if word.isdigit():\n",
    "            filtered_words.append(word)\n",
    "        # Tek harf ama anlamlÄ± ise koru (A blok, B kapÄ±sÄ± vb.)\n",
    "        elif len(word) == 1 and word.isalpha():\n",
    "            # Ã–nceki veya sonraki kelimeye bak\n",
    "            context_words = []\n",
    "            if i > 0:\n",
    "                context_words.append(words[i-1].lower())\n",
    "            if i < len(words) - 1:\n",
    "                context_words.append(words[i+1].lower())\n",
    "            \n",
    "            # Blok, kapi, daire vb. baÄŸlamÄ±nda tek harf anlamlÄ±dÄ±r\n",
    "            meaningful_contexts = ['blok', 'kapi', 'kapisi', 'daire', 'apartmani', 'sitesi', 'mahallesi']\n",
    "            if any(ctx in meaningful_contexts for ctx in context_words):\n",
    "                filtered_words.append(word)\n",
    "            # Yoksa Ã§ok kÄ±sa kelimeyi atla\n",
    "        # Normal kelimeler (2+ karakter)\n",
    "        elif len(word) >= 2:\n",
    "            filtered_words.append(word)\n",
    "    \n",
    "    text = ' '.join(filtered_words)\n",
    "    \n",
    "    # --- PHASE 10: FEATURE INTEGRATION ---\n",
    "    # Feature'larÄ± metne entegre et (BERT iÃ§in ek sinyal)\n",
    "    if features:\n",
    "        feature_string = ' '.join(features)\n",
    "        text = f\"{text} {feature_string}\"\n",
    "    \n",
    "    # Final temizlik\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0693bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 4060 Ti\n",
      "Veri seti: 848237 satÄ±r\n",
      "SÄ±nÄ±f sayÄ±sÄ±: 10390\n",
      "ðŸ“Š Yeni preprocessing uygulanÄ±yor...\n",
      "Veri seti: 848237 satÄ±r\n",
      "SÄ±nÄ±f sayÄ±sÄ±: 10390\n",
      "ðŸ“Š Yeni preprocessing uygulanÄ±yor...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 37\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# --- 4. YENÄ° BERT-OPTIMIZED PREPROCESSING ---\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# YENÄ° OPTIMIZE EDÄ°LMÄ°Åž PREPROCESSING KULLAN\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“Š Yeni preprocessing uygulanÄ±yor...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maddress_bert_optimized\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maddress\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbert_optimized_address_preprocessing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Preprocessing karÅŸÄ±laÅŸtÄ±rmasÄ±\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mðŸ“Š BERT-Optimized Preprocessing Ã¶rnekleri:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\pandas\\core\\series.py:4935\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4800\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4801\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4802\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4807\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4808\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4809\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4810\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4811\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4926\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4927\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4928\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4929\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4930\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4931\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4933\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4934\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4935\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\pandas\\core\\apply.py:1422\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1419\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1421\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1422\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\pandas\\core\\apply.py:1502\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1500\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1501\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1502\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\pandas\\core\\base.py:925\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    923\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2999\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[1], line 146\u001b[0m, in \u001b[0;36mbert_optimized_address_preprocessing\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    128\u001b[0m major_locations \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbist\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mistanbul\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    130\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbistanbul\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mistanbul\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbbahcelievler\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbahcelievler\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    143\u001b[0m }\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m location_pattern, standardized \u001b[38;5;129;01min\u001b[39;00m major_locations\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 146\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation_pattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstandardized\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIGNORECASE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# --- PHASE 7: NOISE REMOVAL ---\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# Gereksiz kelime ve ifadeleri kaldÄ±r\u001b[39;00m\n\u001b[0;32m    150\u001b[0m noise_patterns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbmevki\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbmevkii\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbyakini\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbcivarÄ±\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbkarsisi\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbkarsisinda\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbyani\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbyaninda\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    153\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbonu\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbonunde\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbarkasi\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbarkasinda\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbiÃ§inde\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbiÃ§erisinde\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbuzerinde\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mbaltinda\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m    155\u001b[0m ]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- 1. Gerekli KÃ¼tÃ¼phanelerin YÃ¼klenmesi ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, TrainerCallback\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
    "\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"None\")\n",
    "\n",
    "# --- 2. Veri YÃ¼kleme ---\n",
    "df_full = pd.read_csv('train.csv')\n",
    "\n",
    "label_counts = df_full['label'].value_counts()\n",
    "top_100_labels = label_counts.head(10390).index.tolist()\n",
    "df = df_full[df_full['label'].isin(top_100_labels)].copy()\n",
    "print(f\"Veri seti: {len(df)} satÄ±r\")\n",
    "\n",
    "df = df.dropna(subset=['address', 'label'])\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "# --- 3. Label Encoding ---\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_label'] = label_encoder.fit_transform(df['label'])\n",
    "num_labels = len(label_encoder.classes_)\n",
    "print(f\"SÄ±nÄ±f sayÄ±sÄ±: {num_labels}\")\n",
    "\n",
    "# --- 4. YENÄ° BERT-OPTIMIZED PREPROCESSING ---\n",
    "\n",
    "# YENÄ° OPTIMIZE EDÄ°LMÄ°Åž PREPROCESSING KULLAN\n",
    "print(\"ðŸ“Š Yeni preprocessing uygulanÄ±yor...\")\n",
    "df['address_bert_optimized'] = df['address'].apply(bert_optimized_address_preprocessing)\n",
    "\n",
    "# Preprocessing karÅŸÄ±laÅŸtÄ±rmasÄ±\n",
    "print(\"\\nðŸ“Š BERT-Optimized Preprocessing Ã¶rnekleri:\")\n",
    "for i in range(5):\n",
    "    original = df['address'].iloc[i]\n",
    "    optimized = df['address_bert_optimized'].iloc[i]\n",
    "    print(f\"\\n{i+1}. Ã–rnek:\")\n",
    "    print(f\"   ðŸ“ Orijinal:  '{original}'\")\n",
    "    print(f\"   ðŸŽ¯ Optimized: '{optimized}'\")\n",
    "    print(f\"   ðŸ“ Uzunluk:   {len(original)} â†’ {len(optimized)} karakter\")\n",
    "\n",
    "# BERT-optimized veriyi kullan - TÃœM VERÄ° Ä°LE EÄžÄ°TÄ°M\n",
    "print(\"ðŸŽ¯ TÃœM VERÄ° Ä°LE EÄžÄ°TÄ°M YAPILIYOR (VALIDATION YOK)\")\n",
    "X_full = df['address_bert_optimized'].tolist()\n",
    "y_full = df['encoded_label'].tolist()\n",
    "\n",
    "print(f\"\\nâœ… BERT-optimized preprocessing tamamlandÄ±!\")\n",
    "print(f\"ðŸ“Š Ortalama adres uzunluÄŸu: {df['address_bert_optimized'].str.len().mean():.1f} karakter\")\n",
    "print(f\"ðŸ“Š FULL Training set: {len(X_full):,} samples\")\n",
    "print(f\"ðŸ“Š Validation set: NONE (tÃ¼m veri eÄŸitimde kullanÄ±lÄ±yor)\")\n",
    "\n",
    "# --- 5. BERT Model ---\n",
    "model_name = \"dbmdz/bert-base-turkish-cased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
    "\n",
    "# --- 6. Tokenization ---\n",
    "print(\"Tokenizasyon baÅŸlÄ±yor - TÃœM VERÄ°...\")\n",
    "full_encodings = tokenizer(X_full, truncation=True, padding=True, max_length=256)\n",
    "print(\"Tokenizasyon tamamlandÄ±.\")\n",
    "\n",
    "# --- 7. Dataset ---\n",
    "class AddressDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "full_dataset = AddressDataset(full_encodings, y_full)\n",
    "print(f\"ðŸ“Š Full dataset hazÄ±r: {len(full_dataset):,} samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df51a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… OPTIMIZED Focal Loss classes loaded! ðŸš€\n",
      "âš¡ Initialization should be much faster now!\n",
      "ðŸŽ¯ Reduced computational overhead for training callback\n"
     ]
    }
   ],
   "source": [
    "# --- OPTIMIZED Class-wise Focal Loss Implementation ---\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import Trainer, TrainerCallback\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "class ClassWiseFocalLoss(nn.Module):\n",
    "    \"\"\"\n",
    "    OPTIMIZED Class-wise Focal Loss - Simplified for faster execution\n",
    "    \n",
    "    KEY OPTIMIZATIONS:\n",
    "    - Simplified alpha calculation (no complex scaling)\n",
    "    - Pre-computed alpha tensor\n",
    "    - Reduced computational overhead\n",
    "    - Faster initialization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, class_frequencies, gamma=1.5, alpha_mode='inverse_freq', reduction='mean'):\n",
    "        super(ClassWiseFocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        \n",
    "        # SIMPLIFIED alpha hesaplama - daha hÄ±zlÄ±\n",
    "        if alpha_mode == 'inverse_freq':\n",
    "            # Basit inverse frequency (no complex scaling)\n",
    "            max_freq = max(class_frequencies)\n",
    "            # Simple scaling: rare classes get higher alpha\n",
    "            self.alphas = [min(max_freq / freq, 2.0) for freq in class_frequencies]\n",
    "        else:\n",
    "            # Default equal weighting\n",
    "            self.alphas = [1.0] * len(class_frequencies)\n",
    "            \n",
    "        # Tensor'a Ã§evir ve register et\n",
    "        self.register_buffer('alpha_tensor', torch.FloatTensor(self.alphas))\n",
    "        \n",
    "        print(f\"ðŸŽ¯ Focal Loss kuruldu: Î³={gamma}, Î±_range={min(self.alphas):.2f}-{max(self.alphas):.2f}\")\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        alpha_t = self.alpha_tensor.to(targets.device)[targets]\n",
    "        focal_loss = alpha_t * (1-pt)**self.gamma * ce_loss\n",
    "        \n",
    "        return focal_loss.mean() if self.reduction == 'mean' else focal_loss\n",
    "\n",
    "# OPTIMIZED Custom Trainer \n",
    "class ClassWiseFocalLossTrainer(Trainer):\n",
    "    def __init__(self, *args, train_labels=None, gamma=1.5, alpha_mode='inverse_freq', **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        if train_labels is None:\n",
    "            raise ValueError(\"train_labels gerekli\")\n",
    "            \n",
    "        # SIMPLIFIED class frequency calculation\n",
    "        label_counts = Counter(train_labels)\n",
    "        max_label = max(label_counts.keys())\n",
    "        class_frequencies = [label_counts.get(i, 1) for i in range(max_label + 1)]\n",
    "        \n",
    "        self.focal_loss = ClassWiseFocalLoss(\n",
    "            class_frequencies=class_frequencies,\n",
    "            gamma=gamma,\n",
    "            alpha_mode=alpha_mode\n",
    "        )\n",
    "        \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        loss = self.focal_loss(logits, labels)\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "# SIMPLIFIED Training callback - Reduced computational overhead\n",
    "class DetailedTrainingCallback(TrainerCallback):\n",
    "    def __init__(self, label_encoder=None, num_classes=None):\n",
    "        self.logged_steps = set()\n",
    "        self.eval_count = 0\n",
    "        # OPTIMIZATION: Reduce detailed analysis frequency\n",
    "        self.detailed_analysis_frequency = 3  # Only every 3rd evaluation\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and 'learning_rate' in logs:\n",
    "            step = state.global_step\n",
    "            if step not in self.logged_steps and step % 2000 == 0:  # Log less frequently\n",
    "                print(f\"ðŸ“ˆ Step {step}: LR = {logs['learning_rate']:.2e}\")\n",
    "                self.logged_steps.add(step)\n",
    "    \n",
    "    def on_evaluate(self, args, state, control, logs=None, model=None, **kwargs):\n",
    "        \"\"\"OPTIMIZED evaluation with reduced computational load\"\"\"\n",
    "        if logs and model is not None:\n",
    "            self.eval_count += 1\n",
    "            print(f\"\\nðŸ” EVAL #{self.eval_count} - STEP {state.global_step}\")\n",
    "            \n",
    "            # Basic metrics always\n",
    "            if 'eval_loss' in logs:\n",
    "                print(f\"ðŸ“Š Loss: {logs['eval_loss']:.4f}\")\n",
    "            if 'eval_f1' in logs:\n",
    "                print(f\"ðŸ“Š F1: {logs['eval_f1']:.4f}\")\n",
    "            \n",
    "            # OPTIMIZATION: Detailed analysis only occasionally\n",
    "            if self.eval_count % self.detailed_analysis_frequency == 0:\n",
    "                print(\"ðŸ” Detailed analysis...\")\n",
    "                self._quick_metrics_analysis(model)\n",
    "            else:\n",
    "                print(\"âš¡ Quick evaluation (detailed analysis skipped)\")\n",
    "    \n",
    "    def _quick_metrics_analysis(self, model):\n",
    "        \"\"\"SIMPLIFIED metrics analysis - much faster\"\"\"\n",
    "        try:\n",
    "            # Just print basic info without heavy computation\n",
    "            print(f\"ðŸ“Š Model on device: {next(model.parameters()).device}\")\n",
    "            print(f\"ðŸ“Š Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "            print(\"âœ… Quick analysis complete\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Analysis error: {str(e)[:50]}...\")\n",
    "\n",
    "# SIMPLIFIED Metrics function\n",
    "def compute_enhanced_metrics(eval_pred):\n",
    "    \"\"\"OPTIMIZED metrics computation\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # Handle different input types efficiently\n",
    "    if hasattr(predictions, 'logits'):\n",
    "        predictions = predictions.logits\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "    \n",
    "    # Convert to numpy efficiently\n",
    "    if hasattr(predictions, 'cpu'):\n",
    "        predictions = predictions.cpu().numpy()\n",
    "    if hasattr(labels, 'cpu'):\n",
    "        labels = labels.cpu().numpy()\n",
    "    \n",
    "    # Get predictions and compute F1\n",
    "    if len(predictions.shape) > 1:\n",
    "        predictions = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    f1 = f1_score(labels, predictions, average='macro')\n",
    "    return {'f1': f1}\n",
    "\n",
    "# OPTIMIZED Logits preprocessing\n",
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    \"\"\"Memory-efficient logits preprocessing\"\"\"\n",
    "    return torch.argmax(logits, dim=-1), labels\n",
    "\n",
    "print(\"âœ… OPTIMIZED Focal Loss classes loaded! ðŸš€\")\n",
    "print(\"âš¡ Initialization should be much faster now!\")\n",
    "print(\"ðŸŽ¯ Reduced computational overhead for training callback\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dc45f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ GPU belleÄŸi temizleniyor ve model yÃ¼kleniyor...\n",
      "âœ… GPU belleÄŸi temizlendi\n",
      "ðŸ“‚ Model yÃ¼kleniyor: C:\\Users\\bicer\\OneDrive\\MasaÃ¼stÃ¼\\hepsiburada-hackathon-kaggle-etabi\\results_focal_loss\\checkpoint-106000\n",
      "âœ… Model yÃ¼klendi\n",
      "âœ… Model yÃ¼klendi\n",
      "ðŸ“Š Focal Loss Training: 721,001 samples\n",
      "ðŸ“Š Evaluation (metrics iÃ§in): 127,236 samples\n",
      "ðŸ“Š Focal Loss Training: 721,001 samples\n",
      "ðŸ“Š Evaluation (metrics iÃ§in): 127,236 samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mðŸ“Š Evaluation (metrics iÃ§in): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(X_eval_focal)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Tokenization for Focal Loss\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m train_encodings_focal \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_focal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m eval_encodings_focal \u001b[38;5;241m=\u001b[39m tokenizer(X_eval_focal, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Datasets\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2910\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[0;32m   2908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[0;32m   2909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[1;32m-> 2910\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_one(text\u001b[38;5;241m=\u001b[39mtext, text_pair\u001b[38;5;241m=\u001b[39mtext_pair, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mall_kwargs)\n\u001b[0;32m   2911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2912\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2998\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   2993\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2994\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2995\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2996\u001b[0m         )\n\u001b[0;32m   2997\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[1;32m-> 2998\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[0;32m   2999\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   3000\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   3001\u001b[0m         padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3002\u001b[0m         truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   3003\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   3004\u001b[0m         stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   3005\u001b[0m         is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   3006\u001b[0m         pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3007\u001b[0m         padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[0;32m   3008\u001b[0m         return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   3009\u001b[0m         return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   3010\u001b[0m         return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   3011\u001b[0m         return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   3012\u001b[0m         return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   3013\u001b[0m         return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   3014\u001b[0m         return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   3015\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3016\u001b[0m         split_special_tokens\u001b[38;5;241m=\u001b[39msplit_special_tokens,\n\u001b[0;32m   3017\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3018\u001b[0m     )\n\u001b[0;32m   3019\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3020\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[0;32m   3021\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[0;32m   3022\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3040\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3041\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:3199\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m   3189\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[0;32m   3190\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[0;32m   3191\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[0;32m   3192\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3196\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3197\u001b[0m )\n\u001b[1;32m-> 3199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_batch_encode_plus(\n\u001b[0;32m   3200\u001b[0m     batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[0;32m   3201\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   3202\u001b[0m     padding_strategy\u001b[38;5;241m=\u001b[39mpadding_strategy,\n\u001b[0;32m   3203\u001b[0m     truncation_strategy\u001b[38;5;241m=\u001b[39mtruncation_strategy,\n\u001b[0;32m   3204\u001b[0m     max_length\u001b[38;5;241m=\u001b[39mmax_length,\n\u001b[0;32m   3205\u001b[0m     stride\u001b[38;5;241m=\u001b[39mstride,\n\u001b[0;32m   3206\u001b[0m     is_split_into_words\u001b[38;5;241m=\u001b[39mis_split_into_words,\n\u001b[0;32m   3207\u001b[0m     pad_to_multiple_of\u001b[38;5;241m=\u001b[39mpad_to_multiple_of,\n\u001b[0;32m   3208\u001b[0m     padding_side\u001b[38;5;241m=\u001b[39mpadding_side,\n\u001b[0;32m   3209\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mreturn_tensors,\n\u001b[0;32m   3210\u001b[0m     return_token_type_ids\u001b[38;5;241m=\u001b[39mreturn_token_type_ids,\n\u001b[0;32m   3211\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mreturn_attention_mask,\n\u001b[0;32m   3212\u001b[0m     return_overflowing_tokens\u001b[38;5;241m=\u001b[39mreturn_overflowing_tokens,\n\u001b[0;32m   3213\u001b[0m     return_special_tokens_mask\u001b[38;5;241m=\u001b[39mreturn_special_tokens_mask,\n\u001b[0;32m   3214\u001b[0m     return_offsets_mapping\u001b[38;5;241m=\u001b[39mreturn_offsets_mapping,\n\u001b[0;32m   3215\u001b[0m     return_length\u001b[38;5;241m=\u001b[39mreturn_length,\n\u001b[0;32m   3216\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   3217\u001b[0m     split_special_tokens\u001b[38;5;241m=\u001b[39msplit_special_tokens,\n\u001b[0;32m   3218\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   3219\u001b[0m )\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\transformers\\tokenization_utils.py:887\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus\u001b[1;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, padding_side, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    885\u001b[0m     ids, pair_ids \u001b[38;5;241m=\u001b[39m ids_or_pair_ids\n\u001b[1;32m--> 887\u001b[0m first_ids \u001b[38;5;241m=\u001b[39m \u001b[43mget_input_ids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    888\u001b[0m second_ids \u001b[38;5;241m=\u001b[39m get_input_ids(pair_ids) \u001b[38;5;28;01mif\u001b[39;00m pair_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    889\u001b[0m input_ids\u001b[38;5;241m.\u001b[39mappend((first_ids, second_ids))\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\transformers\\tokenization_utils.py:854\u001b[0m, in \u001b[0;36mPreTrainedTokenizer._batch_encode_plus.<locals>.get_input_ids\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_input_ids\u001b[39m(text):\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 854\u001b[0m         tokens \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenize(text, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_tokens_to_ids(tokens)\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(text) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(text[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\transformers\\tokenization_utils.py:697\u001b[0m, in \u001b[0;36mPreTrainedTokenizer.tokenize\u001b[1;34m(self, text, **kwargs)\u001b[0m\n\u001b[0;32m    695\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mappend(token)\n\u001b[0;32m    696\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 697\u001b[0m         tokenized_text\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    698\u001b[0m \u001b[38;5;66;03m# [\"This\", \" is\", \" something\", \"<special_token_1>\", \"else\"]\u001b[39;00m\n\u001b[0;32m    699\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tokenized_text\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\transformers\\models\\bert\\tokenization_bert.py:161\u001b[0m, in \u001b[0;36mBertTokenizer._tokenize\u001b[1;34m(self, text, split_special_tokens)\u001b[0m\n\u001b[0;32m    159\u001b[0m split_tokens \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    160\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_basic_tokenize:\n\u001b[1;32m--> 161\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbasic_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnever_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall_special_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[0;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# If the token is part of the never_split set\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbasic_tokenizer\u001b[38;5;241m.\u001b[39mnever_split:\n\u001b[0;32m    166\u001b[0m             split_tokens\u001b[38;5;241m.\u001b[39mappend(token)\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\transformers\\models\\bert\\tokenization_bert.py:332\u001b[0m, in \u001b[0;36mBasicTokenizer.tokenize\u001b[1;34m(self, text, never_split)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip_accents:\n\u001b[0;32m    331\u001b[0m             token \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_strip_accents(token)\n\u001b[1;32m--> 332\u001b[0m     split_tokens\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_split_on_punc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnever_split\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    334\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m whitespace_tokenize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(split_tokens))\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output_tokens\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\transformers\\models\\bert\\tokenization_bert.py:358\u001b[0m, in \u001b[0;36mBasicTokenizer._run_split_on_punc\u001b[1;34m(self, text, never_split)\u001b[0m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(chars):\n\u001b[0;32m    357\u001b[0m     char \u001b[38;5;241m=\u001b[39m chars[i]\n\u001b[1;32m--> 358\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43m_is_punctuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchar\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    359\u001b[0m         output\u001b[38;5;241m.\u001b[39mappend([char])\n\u001b[0;32m    360\u001b[0m         start_new_word \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda\\envs\\Pytorch\\lib\\site-packages\\transformers\\tokenization_utils.py:368\u001b[0m, in \u001b[0;36m_is_punctuation\u001b[1;34m(char)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_is_punctuation\u001b[39m(char):\n\u001b[0;32m    367\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Checks whether `char` is a punctuation character.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 368\u001b[0m     cp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mord\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     \u001b[38;5;66;03m# We treat all non-letter/number ASCII as punctuation.\u001b[39;00m\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;66;03m# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode\u001b[39;00m\n\u001b[0;32m    371\u001b[0m     \u001b[38;5;66;03m# Punctuation class but we treat them as punctuation anyways, for\u001b[39;00m\n\u001b[0;32m    372\u001b[0m     \u001b[38;5;66;03m# consistency.\u001b[39;00m\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m33\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m47\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m58\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m91\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m96\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (cp \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m123\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m cp \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m126\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# --- FULL DATA FINE-TUNING WITH FOCAL LOSS ---\n",
    "print(\"ðŸ”„ GPU belleÄŸi temizleniyor ve model yÃ¼kleniyor...\")\n",
    "\n",
    "# GPU belleÄŸini temizle\n",
    "if 'model' in locals():\n",
    "    del model\n",
    "if 'trainer' in locals():\n",
    "    del trainer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"âœ… GPU belleÄŸi temizlendi\")\n",
    "\n",
    "# Model yolunu belirle\n",
    "model_path = r\"C:\\Users\\bicer\\OneDrive\\MasaÃ¼stÃ¼\\hepsiburada-hackathon-kaggle-etabi\\results_focal_loss\\checkpoint-106000\"\n",
    "print(f\"ðŸ“‚ Model yÃ¼kleniyor: {model_path}\")\n",
    "\n",
    "# Model ve tokenizer'Ä± yÃ¼kle\n",
    "model = BertForSequenceClassification.from_pretrained(model_path, num_labels=num_labels)\n",
    "model.to(\"cuda\")\n",
    "\n",
    "print(\"âœ… Model yÃ¼klendi\")\n",
    "\n",
    "# EVALUATION Ä°Ã‡Ä°N KÃœÃ‡ÃœK BÄ°R VALÄ°DATÄ°ON SET OLUÅžTUR\n",
    "# (Sadece metrics iÃ§in - asÄ±l eÄŸitim full data ile)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Full data'dan %15'ini evaluation iÃ§in ayÄ±r\n",
    "X_train_focal, X_eval_focal, y_train_focal, y_eval_focal = train_test_split(\n",
    "    X_full, y_full, test_size=0.15, random_state=42, stratify=y_full\n",
    ")\n",
    "\n",
    "print(f\"ðŸ“Š Focal Loss Training: {len(X_train_focal):,} samples\")\n",
    "print(f\"ðŸ“Š Evaluation (metrics iÃ§in): {len(X_eval_focal):,} samples\")\n",
    "\n",
    "# Tokenization for Focal Loss\n",
    "train_encodings_focal = tokenizer(X_train_focal, truncation=True, padding=True, max_length=256)\n",
    "eval_encodings_focal = tokenizer(X_eval_focal, truncation=True, padding=True, max_length=256)\n",
    "\n",
    "# Datasets\n",
    "train_dataset_focal = AddressDataset(train_encodings_focal, y_train_focal)\n",
    "eval_dataset_focal = AddressDataset(eval_encodings_focal, y_eval_focal)\n",
    "\n",
    "print(\"âœ… Focal Loss datasets hazÄ±r\")\n",
    "\n",
    "# FOCAL LOSS TRAINING AYARLARI\n",
    "focal_training_args = TrainingArguments(\n",
    "    output_dir='./final_full_training_focal',\n",
    "    num_train_epochs=5,                    # Focal Loss iÃ§in biraz daha fazla epoch\n",
    "    per_device_train_batch_size=96,        # Focal Loss iÃ§in optimize batch size\n",
    "    per_device_eval_batch_size=96,         \n",
    "    learning_rate=2e-4,                    # Focal Loss iÃ§in optimize LR\n",
    "    warmup_steps=8000,                     \n",
    "    weight_decay=0.01,\n",
    "    lr_scheduler_type=\"linear\",      \n",
    "    eval_strategy=\"steps\",                 # Evaluation aktif\n",
    "    eval_steps=1000,                       # Her 2000 step'te eval\n",
    "    save_strategy=\"steps\",           \n",
    "    save_steps=1000,                       # Save daha seyrek\n",
    "    load_best_model_at_end=True,           \n",
    "    save_total_limit=3,                    \n",
    "    metric_for_best_model=\"f1\",            \n",
    "    greater_is_better=True,                \n",
    "    report_to=[],\n",
    "    logging_steps=1000,\n",
    "    fp16=True,\n",
    "    seed=42,\n",
    "    max_grad_norm=1.0\n",
    ")\n",
    "\n",
    "# Enhanced callback with detailed metrics\n",
    "detailed_callback = DetailedTrainingCallback(\n",
    "    label_encoder=label_encoder, \n",
    "    num_classes=num_labels\n",
    ")\n",
    "\n",
    "# Focal Loss trainer\n",
    "focal_trainer = ClassWiseFocalLossTrainer(\n",
    "    model=model,\n",
    "    args=focal_training_args,\n",
    "    train_dataset=train_dataset_focal,\n",
    "    eval_dataset=eval_dataset_focal,\n",
    "    compute_metrics=compute_enhanced_metrics,\n",
    "    callbacks=[detailed_callback],\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics,\n",
    "    train_labels=y_train_focal,            # SÄ±nÄ±f bazlÄ± alpha iÃ§in gerekli\n",
    "    gamma=1.5,                             # Optimal gamma\n",
    "    alpha_mode='inverse_freq'              # Inverse frequency weighting\n",
    ")\n",
    "\n",
    "print(\"âœ… Focal Loss trainer hazÄ±rlandÄ±\")\n",
    "print(f\"ðŸ“Š Training samples: {len(train_dataset_focal):,}\")\n",
    "print(f\"ðŸ“Š Evaluation samples: {len(eval_dataset_focal):,}\")\n",
    "print(f\"ðŸ“Š Epoch sayÄ±sÄ±: {focal_training_args.num_train_epochs}\")\n",
    "print(f\"ðŸ“Š Batch size: {focal_training_args.per_device_train_batch_size}\")\n",
    "print(f\"ðŸ“Š Evaluation: Her {focal_training_args.eval_steps} step'te\")\n",
    "\n",
    "# FOCAL LOSS TRAINING BAÅžLAT\n",
    "print(\"\\nðŸš€ FOCAL LOSS TRAINING BAÅžLIYOR...\")\n",
    "print(\"ðŸŽ¯ Her evaluation'da TP, FP, TN, FN detaylarÄ± gÃ¶sterilecek!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "train_result = focal_trainer.train()\n",
    "\n",
    "print(\"\\nâœ… FOCAL LOSS TRAINING TAMAMLANDI!\")\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“ˆ Final Results:\")\n",
    "print(f\"   â€¢ Training Loss: {train_result.training_loss:.4f}\")\n",
    "if hasattr(train_result, 'metrics'):\n",
    "    for key, value in train_result.metrics.items():\n",
    "        if isinstance(value, (int, float)):\n",
    "            print(f\"   â€¢ {key}: {value:.4f}\")\n",
    "\n",
    "# Final evaluation with detailed metrics\n",
    "print(\"\\nðŸ” FINAL EVALUATION...\")\n",
    "eval_result = focal_trainer.evaluate()\n",
    "print(\"ðŸ“Š Final Evaluation Results:\")\n",
    "for key, value in eval_result.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"   â€¢ {key}: {value:.4f}\")\n",
    "\n",
    "# Final modeli kaydet\n",
    "focal_save_path = \"./kaggle_full_model_focal\"\n",
    "print(f\"\\nðŸ’¾ Focal Loss model kaydediliyor: {focal_save_path}\")\n",
    "focal_trainer.save_model(focal_save_path)\n",
    "tokenizer.save_pretrained(focal_save_path)\n",
    "\n",
    "# Label encoder'Ä± da kaydet\n",
    "import joblib\n",
    "joblib.dump(label_encoder, f\"{focal_save_path}/label_encoder.pkl\")\n",
    "\n",
    "print(f\"âœ… FOCAL LOSS TRAINING TAMAMLANDI!\")\n",
    "print(f\"ðŸ“ Focal Loss Kaggle model: {focal_save_path}\")\n",
    "print(f\"ðŸŽ¯ Bu model Class-wise Focal Loss ile eÄŸitildi!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b459242a",
   "metadata": {},
   "source": [
    "# ðŸ“ˆ Training Visualization - Focal Loss Results\n",
    "\n",
    "## Bu bÃ¶lÃ¼m:\n",
    "- Training/validation loss grafikleri\n",
    "- F1 score geliÅŸimi  \n",
    "- Learning rate schedule\n",
    "- Focal Loss eÄŸitim Ã¶zeti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7fe8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- FOCAL LOSS EÄžÄ°TÄ°M GRAFÄ°KLERÄ° ---\n",
    "print(\"\\n--- FOCAL LOSS EÄžÄ°TÄ°M GRAFÄ°KLERÄ° Ã‡Ä°ZÄ°LÄ°YOR ---\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # Training history'den verileri Ã§ek\n",
    "    history = focal_trainer.state.log_history\n",
    "    \n",
    "    # Training ve validation verilerini ayÄ±r\n",
    "    train_logs = [log for log in history if 'loss' in log and 'eval_loss' not in log]\n",
    "    eval_logs = [log for log in history if 'eval_loss' in log]\n",
    "    \n",
    "    # Veri Ã§erÃ§eveleri oluÅŸtur\n",
    "    train_df = pd.DataFrame(train_logs)\n",
    "    eval_df = pd.DataFrame(eval_logs)\n",
    "    \n",
    "    # 2x2 subplot oluÅŸtur\n",
    "    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    fig.suptitle('ðŸŽ¯ FOCAL LOSS Fine-tuning EÄŸitim SonuÃ§larÄ±', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Training vs Validation Loss (AynÄ± grafikte)\n",
    "    if not train_df.empty and 'loss' in train_df.columns:\n",
    "        ax1.plot(train_df['step'], train_df['loss'], 'b-', linewidth=2, label='Training Loss', alpha=0.8)\n",
    "    if not eval_df.empty and 'eval_loss' in eval_df.columns:\n",
    "        ax1.plot(eval_df['step'], eval_df['eval_loss'], 'r-', linewidth=2, label='Validation Loss', alpha=0.8)\n",
    "    \n",
    "    ax1.set_title('ðŸ”¥ Focal Loss: Training vs Validation', fontweight='bold')\n",
    "    ax1.set_xlabel('Step')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # En dÃ¼ÅŸÃ¼k loss'larÄ± gÃ¶ster\n",
    "    if not train_df.empty and 'loss' in train_df.columns:\n",
    "        min_train_loss = train_df['loss'].min()\n",
    "        ax1.axhline(y=min_train_loss, color='blue', linestyle='--', alpha=0.5)\n",
    "    if not eval_df.empty and 'eval_loss' in eval_df.columns:\n",
    "        min_val_loss = eval_df['eval_loss'].min()\n",
    "        ax1.axhline(y=min_val_loss, color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 2. F1 Score Progression\n",
    "    if not eval_df.empty and 'eval_f1' in eval_df.columns:\n",
    "        ax2.plot(eval_df['step'], eval_df['eval_f1'], 'g-', linewidth=3, label='F1 Score', marker='o', markersize=4)\n",
    "        ax2.set_title('ðŸŽ¯ F1 Score GeliÅŸimi (Validation)', fontweight='bold')\n",
    "        ax2.set_xlabel('Step')\n",
    "        ax2.set_ylabel('F1 Score')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        # En iyi F1 score'u gÃ¶ster\n",
    "        best_f1 = eval_df['eval_f1'].max()\n",
    "        best_step = eval_df.loc[eval_df['eval_f1'].idxmax(), 'step']\n",
    "        ax2.axhline(y=best_f1, color='red', linestyle='--', alpha=0.7)\n",
    "        ax2.text(0.02, 0.95, f'ðŸ† En Ä°yi F1: {best_f1:.4f}\\nðŸ“ Step: {best_step}', \n",
    "                transform=ax2.transAxes, fontsize=10, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "        \n",
    "        # F1 score range'ini optimize et\n",
    "        f1_min = eval_df['eval_f1'].min()\n",
    "        f1_max = eval_df['eval_f1'].max()\n",
    "        f1_margin = (f1_max - f1_min) * 0.1\n",
    "        ax2.set_ylim(max(0, f1_min - f1_margin), min(1, f1_max + f1_margin))\n",
    "    \n",
    "    # 3. Learning Rate Schedule\n",
    "    if not train_df.empty and 'learning_rate' in train_df.columns:\n",
    "        ax3.plot(train_df['step'], train_df['learning_rate'], 'purple', linewidth=2, label='Learning Rate')\n",
    "        ax3.set_title('ðŸ“‰ Learning Rate Schedule', fontweight='bold')\n",
    "        ax3.set_xlabel('Step')\n",
    "        ax3.set_ylabel('Learning Rate')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        ax3.legend()\n",
    "        ax3.ticklabel_format(style='scientific', axis='y', scilimits=(0,0))\n",
    "        \n",
    "        # LR deÄŸiÅŸimi gÃ¶ster\n",
    "        initial_lr = train_df['learning_rate'].iloc[0]\n",
    "        final_lr = train_df['learning_rate'].iloc[-1]\n",
    "        ax3.text(0.02, 0.95, f'ðŸš€ BaÅŸlangÄ±Ã§: {initial_lr:.2e}\\nðŸŽ¯ Son: {final_lr:.2e}\\nðŸ“‰ Azalma: {(final_lr/initial_lr)*100:.1f}%', \n",
    "                transform=ax3.transAxes, fontsize=9, verticalalignment='top',\n",
    "                bbox=dict(boxstyle='round', facecolor='lavender', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Dosya adÄ±nÄ± focal loss iÃ§in gÃ¼ncelle\n",
    "    plt.savefig('focal_loss_training_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # FOCAL LOSS Ã–ZET Ä°STATÄ°STÄ°KLER\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ðŸŽ¯ FOCAL LOSS EÄžÄ°TÄ°M Ã–ZETÄ°\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    if not train_df.empty:\n",
    "        final_train_loss = train_df['loss'].iloc[-1]\n",
    "        min_train_loss = train_df['loss'].min()\n",
    "        print(f\"ðŸ”¹ Son Training Loss: {final_train_loss:.4f}\")\n",
    "        print(f\"ðŸ”¹ En DÃ¼ÅŸÃ¼k Training Loss: {min_train_loss:.4f}\")\n",
    "    \n",
    "    if not eval_df.empty:\n",
    "        final_val_loss = eval_df['eval_loss'].iloc[-1]\n",
    "        min_val_loss = eval_df['eval_loss'].min()\n",
    "        best_f1 = eval_df['eval_f1'].max()\n",
    "        final_f1 = eval_df['eval_f1'].iloc[-1]\n",
    "        best_f1_step = eval_df.loc[eval_df['eval_f1'].idxmax(), 'step']\n",
    "        \n",
    "        print(f\"ðŸ”¹ Son Validation Loss: {final_val_loss:.4f}\")\n",
    "        print(f\"ðŸ”¹ En DÃ¼ÅŸÃ¼k Validation Loss: {min_val_loss:.4f}\")\n",
    "        print(f\"ðŸ”¹ ðŸ† En Ä°yi F1 Score: {best_f1:.4f} (Step {best_f1_step})\")\n",
    "        print(f\"ðŸ”¹ Son F1 Score: {final_f1:.4f}\")\n",
    "        \n",
    "        # F1 improvement\n",
    "        if len(eval_df) > 1:\n",
    "            first_f1 = eval_df['eval_f1'].iloc[0]\n",
    "            f1_improvement = best_f1 - first_f1\n",
    "            print(f\"ðŸ”¹ ðŸ“ˆ F1 Ä°yileÅŸmesi: +{f1_improvement:.4f} ({f1_improvement/first_f1*100:.1f}%)\")\n",
    "    \n",
    "    if not train_df.empty and 'learning_rate' in train_df.columns:\n",
    "        final_lr = train_df['learning_rate'].iloc[-1]\n",
    "        initial_lr = train_df['learning_rate'].iloc[0]\n",
    "        print(f\"ðŸ”¹ BaÅŸlangÄ±Ã§ Learning Rate: {initial_lr:.2e}\")\n",
    "        print(f\"ðŸ”¹ Son Learning Rate: {final_lr:.2e}\")\n",
    "        print(f\"ðŸ”¹ LR Azalma OranÄ±: {(final_lr/initial_lr)*100:.1f}%\")\n",
    "    \n",
    "    # Focal Loss Ã¶zellikleri\n",
    "    print(f\"\\nðŸŽ¯ FOCAL LOSS Ã–ZELLÄ°KLERÄ°:\")\n",
    "    print(f\"ðŸ”¹ Gamma (Î³): {focal_trainer.focal_loss.gamma}\")\n",
    "    print(f\"ðŸ”¹ Alpha Mode: {focal_trainer.focal_loss.alpha_mode}\")\n",
    "    print(f\"ðŸ”¹ Alpha Range: {min(focal_trainer.focal_loss.alphas):.3f} - {max(focal_trainer.focal_loss.alphas):.3f}\")\n",
    "    print(f\"ðŸ”¹ Training Samples: {len(train_dataset_focal):,}\")\n",
    "    print(f\"ðŸ”¹ Validation Samples: {len(eval_dataset_focal):,}\")\n",
    "    print(f\"ðŸ”¹ Batch Size: {focal_training_args.per_device_train_batch_size}\")\n",
    "    print(f\"ðŸ”¹ Epochs: {focal_training_args.num_train_epochs}\")\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"âœ… Focal Loss grafikleri 'focal_loss_training_results.png' olarak kaydedildi!\")\n",
    "    print(\"ðŸŽ¯ Class-wise Focal Loss ile eÄŸitim baÅŸarÄ±yla tamamlandÄ±!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Grafik oluÅŸturma hatasÄ±: {e}\")\n",
    "    print(\"âš ï¸ Training history verilerine eriÅŸilemedi.\")\n",
    "    \n",
    "    # Alternatif basit Ã¶zet\n",
    "    try:\n",
    "        if 'train_result' in locals():\n",
    "            print(f\"\\nðŸ“Š Basit EÄŸitim Ã–zeti:\")\n",
    "            print(f\"ðŸ”¹ Final Training Loss: {train_result.training_loss:.4f}\")\n",
    "            if hasattr(train_result, 'metrics'):\n",
    "                for key, value in train_result.metrics.items():\n",
    "                    if isinstance(value, (int, float)):\n",
    "                        print(f\"ðŸ”¹ {key}: {value:.4f}\")\n",
    "    except:\n",
    "        print(\"âš ï¸ Ã–zet bilgiler de alÄ±namadÄ±.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
